{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4831/299313284.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtml(querry, page):\n",
    "    \n",
    "    headers = {\n",
    "        'authority': 'www.ebay.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7,fr;q=0.6,gu;q=0.5,de;q=0.4',\n",
    "        'dnt': '1',\n",
    "        'referer': 'https://www.ebay.com/sch/i.html?_from=R40&_trksid=p4432023.m570.l1313&_nkw=mobile&_sacat=0',\n",
    "        'sec-ch-ua': '\"Not A(Brand\";v=\"99\", \"Google Chrome\";v=\"121\", \"Chromium\";v=\"121\"',\n",
    "        'sec-ch-ua-full-version': '\"121.0.6167.161\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-model': '\"\"',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "        'sec-ch-ua-platform-version': '\"15.0.0\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        '_from': 'R40',\n",
    "        '_nkw': querry,\n",
    "        '_sacat': '0',\n",
    "        '_pgn': page,\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://www.ebay.com/sch/i.html', params=params, headers=headers)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpageData(querry,page):\n",
    "    ItemList = []\n",
    "    response = getHtml(querry, page)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    AllProduct = soup.find_all('li', class_='s-item s-item__pl-on-bottom')\n",
    "    for data in AllProduct:\n",
    "        if AllProduct.index(data) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            productName  =  data.find('div', class_='s-item__title').text\n",
    "        except:\n",
    "            continue    \n",
    "        productSubtitle = data.find('div', class_='s-item__subtitle').text\n",
    "        try:\n",
    "            productRatingCount  = data.find('div', class_='x-star-rating').text\n",
    "        except :\n",
    "            productRatingCount = '0'\n",
    "        try:\n",
    "            ProductTotalRating = data.find('span', class_='s-item__reviews-count').text\n",
    "        except:\n",
    "            ProductTotalRating = '0'\n",
    "        ProductPrice = data.find('span', class_='s-item__price').text\n",
    "        productshiping=data.find('span',class_='s-item__itemLocation')\n",
    "        if productshiping:\n",
    "            productshiping=productshiping.text.strip()\n",
    "        else:\n",
    "            productshiping='location not available'\n",
    "        productseller=data.find('span',class_='s-item__seller-info')\n",
    "        if productseller:\n",
    "            productseller=productseller.text.strip()\n",
    "        else:\n",
    "            productseller='seller not available'\n",
    "\n",
    "        ProductTotalRating = re.findall(r'^\\d+', ProductTotalRating)[0]\n",
    "        prouducts = {'productName': productName, 'productSubtitle': productSubtitle ,'ProductPrice': ProductPrice  , 'productRatingCount': productRatingCount, 'ProductTotalRating': ProductTotalRating , 'productshiping':productshiping,'productseller':productseller}\n",
    "        ItemList.append(prouducts)\n",
    "    return ItemList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m querry \u001b[38;5;241m=\u001b[39m querry \u001b[38;5;241m+\u001b[39m brand\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m page \u001b[38;5;241m<\u001b[39m totalPages :\n\u001b[0;32m----> 9\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mgetpageData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquerry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(page)\n\u001b[1;32m     11\u001b[0m     TotalData\u001b[38;5;241m.\u001b[39mextend(data)\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mgetpageData\u001b[0;34m(querry, page)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m productName  \u001b[38;5;241m=\u001b[39m  data\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms-item__title\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m---> 10\u001b[0m productSubtitle \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms-item__subtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     productRatingCount  \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-star-rating\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "totalPages =  100\n",
    "target_brands = [\" Rockshox\", \"Shimano\", \"raceface\"]\n",
    "querry = \"mountain biking\"\n",
    "TotalData = []\n",
    "page =1\n",
    "for brand in target_brands:\n",
    "    querry = querry + brand\n",
    "    while page < totalPages :\n",
    "        data = getpageData(querry, page)\n",
    "        print(page)\n",
    "        TotalData.extend(data)\n",
    "        page+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(TotalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ebay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_page_html(query, page):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        '_from': 'R40',\n",
    "        '_nkw': query,\n",
    "        '_sop': '12',  # Sort by Best Match\n",
    "        '_ipg': '100',  # Items per page\n",
    "        '_pgn': page\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://www.ebay.com/sch/i.html', params=params, headers=headers)\n",
    "    return response.text\n",
    "\n",
    "def extract_data_from_page(html, target_brands):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    all_products = soup.find_all('div', class_='s-item__info')\n",
    "\n",
    "    data = []\n",
    "    for product in all_products:\n",
    "        brand_tags = product.find_all('span', class_='s-item__dynamic')\n",
    "        brands = [tag.text.strip() for tag in brand_tags]\n",
    "\n",
    "        # Check if the product has any of the desired brands\n",
    "        if any(brand in brands for brand in target_brands):\n",
    "            seller_name = product.find('span', class_='s-item__seller-info').text.strip()\n",
    "            rating_count = int(re.search(r'\\d+', product.find('span', class_='s-item__reviews-count').text.strip()).group())\n",
    "            price = float(re.search(r'\\d+\\.\\d+', product.find('span', class_='s-item__price').text.strip()).group())\n",
    "\n",
    "            # Filter sellers with several hundred ratings and average item price over $100\n",
    "            if rating_count >= 200 and price > 100:\n",
    "                data.append({'SellerName': seller_name, 'RatingCount': rating_count, 'Price': price, 'Brands': brands})\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_ebay(query, total_pages, target_brands):\n",
    "    all_data = []\n",
    "    for page in range(1, total_pages + 1):\n",
    "        html = get_page_html(query, page)\n",
    "        page_data = extract_data_from_page(html, target_brands)\n",
    "        all_data.extend(page_data)\n",
    "        print(f\"Scraped page {page}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = \"mountain bike\"\n",
    "   \n",
    "    total_pages_to_scrape = int(input(\"Enter the total number of pages to scrape: \"))\n",
    "    scraped_data = scrape_ebay(search_query, total_pages_to_scrape, target_brands)\n",
    "    #Convert data to DataFrame\n",
    "    dataframe = pd.DataFrame(scraped_data)\n",
    "    # Save data to Excel\n",
    "    dataframe.to_excel(f\"{search_query}_ebay_data.xlsx\", index=False)\n",
    "    print(\"Scraping completed. Data saved to Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
